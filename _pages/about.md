---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Yuzhen Liu

My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).


# ğŸ”¥ News
- *2022.02*: &nbsp;ğŸ‰ğŸ‰ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;ğŸ‰ğŸ‰ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ“ Publications 

<!-- 1 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">JAS</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Visual Object Tracking and Servoing Control of a Nano-Scale Quadrotor: System, Algorithms, and Experiments](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) in **IEEE/CAA Journal of Automatica Sinica**, vol.
8, no. 2, pp. 344-360, 2021.

**Yuzhen Liu**, Ziyang Meng, Yao Zou, Ming Cao

<!-- [**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=t5gN6kIAAAAJ&citation_for_view=t5gN6kIAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- Nano-quadrotor. 
</div>
</div>

<!-- 2 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TIM</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Online Temporal Calibration Based on Modified Projection Model for Visual-Inertial Odometry](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) in **IEEE Transactions on Instrumentation and Measurement**, vol.
8, no. 2, pp. 344-360, 2021.

**Yuzhen Liu**, Ziyang Meng

<!-- [**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=t5gN6kIAAAAJ&citation_for_view=t5gN6kIAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- Temperal calibration

</div>
</div>


<!-- 3 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">RAL & ICRA2021</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[A Switching-Coupled Backend for Simultaneous Localization and Dynamic Object Tracking](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) in **IEEE Robotics and Automation Letters & 2021 IEEE International Conference on Robotics and Automation (ICRA)**, , vol. 6, no. 2, pp. 1296-1303, 2021.

**Yuzhen Liu**, Jiacheng Liu, Yun Hao, Bowen Deng, Ziyang Meng

<!-- [**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=t5gN6kIAAAAJ&citation_for_view=t5gN6kIAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- Switching-coupled backend for SLOT.

</div>
</div>

<!-- 4 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">RAL</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[PointSLOT: Real-Time Simultaneous Localization and
Object Tracking for Dynamic Environment](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) in **IEEE Robotics and Automation Letters**, vol.
8, no. 2, pp. 344-360, 2021.

Pengkun Zhou\*, **Yuzhen. Liu\***, Ziyang Meng (\*equal contribution)

<!-- [**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=t5gN6kIAAAAJ&citation_for_view=t5gN6kIAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- PointSLOT

</div>
</div>

<!-- 5 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICARCV2018</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Visual Object Tracking For A Nano-scale Quadrotor](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) in **15th International Conference on Control, Automation, Robotics and Vision (ICARCV2018)**, vol.
8, no. 2, pp. 344-360, 2021.

**Yuzhen. Liu**, Ziyang Meng

<!-- [**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=t5gN6kIAAAAJ&citation_for_view=t5gN6kIAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- Nano-quadrotor

</div>
</div>

<!-- 6 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">JAS</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Distributed Control Algorithm for Leaderâ€“Follower Formation Tracking of Multiple Quadrotors: Theory and Experiment](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) in **IEEE/ASME Transactions on Mechatronics**, vol. 26, no. 2, pp. 1095-1105, 2021.

Zixuan Wang, Yao Zou, **Yuzhen Liu**, Ziyang Meng

<!-- [**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=t5gN6kIAAAAJ&citation_for_view=t5gN6kIAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- Leader-Follower

</div>
</div>

<!-- 7 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NMI</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Lifelike Agility and Play in Quadrupedal Robots using Reinforcement Learning and Generative Pre-trained Models](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) accepted by **Nature Machine Intelligence**.

Lei Han\*, Qingxu Zhu\*, Jiapeng Sheng\*, Chong Zhang\*, Tingguang Li\*, Yizheng Zhang\*, He Zhang\*, **Yuzhen Liu**, Cheng Zhou, Rui Zhao, Jie Li, Yufeng Zhang, Rui Wang, Wanchao Chi, Xiong Li, Yonghui Zhu, Lingzhu Xiang, Xiao Teng, Zhengyou Zhang. (\*Equal Contribution)

<!-- [**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=t5gN6kIAAAAJ&citation_for_view=t5gN6kIAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- Life-like.

</div>
</div>

<!-- 8 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">RAL & ICRA2022</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Visual Localization and Mapping Leveraging the Constraints of Local Ground Manifolds](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) in **IEEE Robotics and Automation Letters & 2022 IEEE Interna-tional Conference on Robotics and Automation (ICRA)**, vol. 7, no. 2, pp. 4196-4203, 2022.

Pengkun Zhou, **Yuzhen Liu**, Pengfei Gu, Jiacheng Liu, Ziyang Meng.

<!-- [**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=t5gN6kIAAAAJ&citation_for_view=t5gN6kIAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- Local Ground Manifolds.

</div>
</div>


<!-- 9 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">RAL & IROS2022</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Point cloud registration leveraging structural regularity in Manhattan world](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) in **IEEE Robotics and Automation Letters & IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)**, vol. 7, no. 3, pp. 7888-7895, 2022.

Jiacheng Liu, **Yuzhen Liu**, Ziyang Meng.

<!-- [**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=t5gN6kIAAAAJ&citation_for_view=t5gN6kIAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- Point registration.

</div>
</div>

- [Rangeâ€“Visualâ€“Inertial Odometry with Coarse-to-Fine Image Registration Fusion for UAV Localization](https://github.com), Yun Hao, Mengfan He, **Yuzhen Liu**, Jiacheng Liu, Ziyang Meng, in **Drones**, 2023.

- [Global Visualâ€“Inertial Localization for Autonomous Vehicles with Pre- Built Map](https://github.com), Yun Hao, Jiacheng Liu, **Yuzhen Liu**, Xinyuan Liu, Ziyang Meng, Fei Xing, in **Sensors**, 2023.

- [A collision-free target tracking controller with uncertain disturbance rejection for quadrupedrobots](https://github.com), Shihan Kong, Jinlin Sun, Aocheng Luo, Wanchao Chi, Chong Zhang, Shenghao Zhang, **Yuzhen Liu**, Qiuguo Zhu, Junzhi Yu in **IEEE Transactions on Intelligent Vehicles**, 2023.

- [Learning and Reusing Quadruped Robot Movement Skills from Biological Dogs for Higher-Level Tasks](https://github.com), Qifeng Wan, Aocheng Luo, Yan Meng, Chong Zhang, Wanchao Chi, Shenghao Zhang, **Yuzhen Liu**, Qiuguo Zhu, Shihan Kong, Junzhi Yu, in **Sensors**, 2023.

# ğŸ– Honors and Awards
- 12/2023, è…¾è®¯å“è¶Šç ”å‘å¥–â€”â€”æ ©æ ©å¦‚ç”Ÿçš„å››è¶³æœºå™¨äººé¡¹ç›®å›¢é˜Ÿ
- 12/2023, è…¾è®¯ OUTSTANDING CONTRIBUTOR 
- 12/2022, è…¾è®¯ SEVP æ¿€åŠ±å¥–â€”â€”é¡¹ç›®ä¹‹æ˜Ÿ
- 07/2022, å…¥é€‰è…¾è®¯â€œæŠ€æœ¯å¤§å’–â€è®¡åˆ’
- 12/2020, å”ç«‹æ–°å¥–å­¦é‡‘
- 12/2020 & 12/2021, æ¸…åå¤§å­¦ç»¼åˆä¼˜ç§€ä¸€ç­‰å¥–å­¦é‡‘
- 12/2018, æ¸…åå¤§å­¦ç»¼åˆä¼˜ç§€äºŒç­‰å¥–å­¦é‡‘
- 12/2016, ä¸­å›½ä»ªå™¨ä»ªè¡¨å­¦ä¼šå¥–å­¦é‡‘
- 12/2016, å›½å®¶å¥–å­¦é‡‘
- 08/2016, è¥¿é—¨å­æ¯ä¸­å›½æ™ºèƒ½åˆ¶é€ æŒ‘æˆ˜èµ›å…¨å›½ç‰¹ç­‰å¥–

# ğŸ“– Educations
- 09/2017 - 08/2022, Ph.D. in Precision Instrument, Department of Precision Instrument, Tsinghua University, Beijing, China.
- 09/2013 - 07/2017, Bachelor's in Artificial Intelligence and Automation, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China.

- 2017å¹´9æœˆ - 2022å¹´8æœˆ, åšå£«, æ¸…åå¤§å­¦ç²¾å¯†ä»ªå™¨ç³», ä¸­å›½åŒ—äº¬
- 2013å¹´9æœˆ - 2017å¹´7æœˆï¼Œæœ¬ç§‘, åä¸­ç§‘æŠ€å¤§å­¦äººå·¥æ™ºèƒ½ä¸è‡ªåŠ¨åŒ–å­¦é™¢, ä¸­å›½æ­¦æ±‰

# ğŸ’¬ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# ğŸ’» Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.