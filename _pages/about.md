---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Yuzhen Liu

My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).


# üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìù Publications 

<!-- 1 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">JAS</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Visual Object Tracking and Servoing Control of a Nano-Scale Quadrotor: System, Algorithms, and Experiments](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) in **IEEE/CAA Journal of Automatica Sinica**, vol.
8, no. 2, pp. 344-360, 2021.

**Yuzhen Liu**, Ziyang Meng, Yao Zou, Ming Cao

<!-- [**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=t5gN6kIAAAAJ&citation_for_view=t5gN6kIAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- Nano-quadrotor. 
</div>
</div>

<!-- 2 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TIM</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Online Temporal Calibration Based on Modified Projection Model for Visual-Inertial Odometry](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) in **IEEE Transactions on Instrumentation and Measurement**, vol.
8, no. 2, pp. 344-360, 2021.

**Yuzhen Liu**, Ziyang Meng

<!-- [**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=t5gN6kIAAAAJ&citation_for_view=t5gN6kIAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- Temperal calibration

</div>
</div>


<!-- 3 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">RAL & ICRA2021</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[A Switching-Coupled Backend for Simultaneous Localization and Dynamic Object Tracking](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) in **IEEE Robotics and Automation Letters & 2021 IEEE International Conference on Robotics and Automation (ICRA)**, , vol. 6, no. 2, pp. 1296-1303, 2021.

**Yuzhen Liu**, Jiacheng Liu, Yun Hao, Bowen Deng, Ziyang Meng

<!-- [**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=t5gN6kIAAAAJ&citation_for_view=t5gN6kIAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- Switching-coupled backend for SLOT.

</div>
</div>

<!-- 4 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">RAL</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[PointSLOT: Real-Time Simultaneous Localization and
Object Tracking for Dynamic Environment](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) in **IEEE Robotics and Automation Letters**, vol.
8, no. 2, pp. 344-360, 2021.

Pengkun Zhou\*, **Yuzhen. Liu\***, Ziyang Meng (\*equal contribution)

<!-- [**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=t5gN6kIAAAAJ&citation_for_view=t5gN6kIAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- PointSLOT

</div>
</div>

<!-- 5 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICARCV2018</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Visual Object Tracking For A Nano-scale Quadrotor](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) in **15th International Conference on Control, Automation, Robotics and Vision (ICARCV2018)**, vol.
8, no. 2, pp. 344-360, 2021.

**Yuzhen. Liu**, Ziyang Meng

<!-- [**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=t5gN6kIAAAAJ&citation_for_view=t5gN6kIAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- Nano-quadrotor

</div>
</div>

<!-- 6 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">JAS</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Distributed Control Algorithm for Leader‚ÄìFollower Formation Tracking of Multiple Quadrotors: Theory and Experiment](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) in **IEEE/ASME Transactions on Mechatronics**, vol. 26, no. 2, pp. 1095-1105, 2021.

Zixuan Wang, Yao Zou, **Yuzhen Liu**, Ziyang Meng

<!-- [**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=t5gN6kIAAAAJ&citation_for_view=t5gN6kIAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- Leader-Follower

</div>
</div>

<!-- 7 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NMI</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Lifelike Agility and Play in Quadrupedal Robots using Reinforcement Learning and Generative Pre-trained Models](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) accepted by **Nature Machine Intelligence**.

Lei Han\*, Qingxu Zhu\*, Jiapeng Sheng\*, Chong Zhang\*, Tingguang Li\*, Yizheng Zhang\*, He Zhang\*, **Yuzhen Liu**, Cheng Zhou, Rui Zhao, Jie Li, Yufeng Zhang, Rui Wang, Wanchao Chi, Xiong Li, Yonghui Zhu, Lingzhu Xiang, Xiao Teng, Zhengyou Zhang. (\*Equal Contribution)

<!-- [**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=t5gN6kIAAAAJ&citation_for_view=t5gN6kIAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- Life-like.

</div>
</div>

<!-- 8 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">RAL & ICRA2022</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Visual Localization and Mapping Leveraging the Constraints of Local Ground Manifolds](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) in **IEEE Robotics and Automation Letters & 2022 IEEE Interna-tional Conference on Robotics and Automation (ICRA)**, vol. 7, no. 2, pp. 4196-4203, 2022.

Pengkun Zhou, **Yuzhen Liu**, Pengfei Gu, Jiacheng Liu, Ziyang Meng.

<!-- [**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=t5gN6kIAAAAJ&citation_for_view=t5gN6kIAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- Local Ground Manifolds.

</div>
</div>


<!-- 9 -->
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">RAL & IROS2022</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Point cloud registration leveraging structural regularity in Manhattan world](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) in **IEEE Robotics and Automation Letters & IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)**, vol. 7, no. 3, pp. 7888-7895, 2022.

Jiacheng Liu, **Yuzhen Liu**, Ziyang Meng.

<!-- [**Project**](https://scholar.google.com.hk/citations?view_op=view_citation&hl=zh-CN&user=t5gN6kIAAAAJ&citation_for_view=t5gN6kIAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong> -->
- Point registration.

</div>
</div>

- [Range‚ÄìVisual‚ÄìInertial Odometry with Coarse-to-Fine Image Registration Fusion for UAV Localization](https://github.com), Yun Hao, Mengfan He, **Yuzhen Liu**, Jiacheng Liu, Ziyang Meng, in **Drones**, 2023.

- [Global Visual‚ÄìInertial Localization for Autonomous Vehicles with Pre- Built Map](https://github.com), Yun Hao, Jiacheng Liu, **Yuzhen Liu**, Xinyuan Liu, Ziyang Meng, Fei Xing, in **Sensors**, 2023.

- [A collision-free target tracking controller with uncertain disturbance rejection for quadrupedrobots](https://github.com), Shihan Kong, Jinlin Sun, Aocheng Luo, Wanchao Chi, Chong Zhang, Shenghao Zhang, **Yuzhen Liu**, Qiuguo Zhu, Junzhi Yu in **IEEE Transactions on Intelligent Vehicles**, 2023.

- [Learning and Reusing Quadruped Robot Movement Skills from Biological Dogs for Higher-Level Tasks](https://github.com), Qifeng Wan, Aocheng Luo, Yan Meng, Chong Zhang, Wanchao Chi, Shenghao Zhang, **Yuzhen Liu**, Qiuguo Zhu, Shihan Kong, Junzhi Yu, in **Sensors**, 2023.

# üéñ Honors and Awards
- 12/2023, ËÖæËÆØÂçìË∂äÁ†îÂèëÂ•ñ‚Äî‚ÄîÊ†©Ê†©Â¶ÇÁîüÁöÑÂõõË∂≥Êú∫Âô®‰∫∫È°πÁõÆÂõ¢Èòü
- 12/2023, ËÖæËÆØ OUTSTANDING CONTRIBUTOR 
- 12/2022, ËÖæËÆØ SEVP ÊøÄÂä±Â•ñ‚Äî‚ÄîÈ°πÁõÆ‰πãÊòü
- 07/2022, ÂÖ•ÈÄâËÖæËÆØ‚ÄúÊäÄÊúØÂ§ßÂíñ‚ÄùËÆ°Âàí
- 12/2020, ÂîêÁ´ãÊñ∞Â•ñÂ≠¶Èáë
- 12/2020 & 12/2021, Ê∏ÖÂçéÂ§ßÂ≠¶ÁªºÂêà‰ºòÁßÄ‰∏ÄÁ≠âÂ•ñÂ≠¶Èáë
- 12/2018, Ê∏ÖÂçéÂ§ßÂ≠¶ÁªºÂêà‰ºòÁßÄ‰∫åÁ≠âÂ•ñÂ≠¶Èáë
- 12/2016, ‰∏≠ÂõΩ‰ª™Âô®‰ª™Ë°®Â≠¶‰ºöÂ•ñÂ≠¶Èáë
- 12/2016, ÂõΩÂÆ∂Â•ñÂ≠¶Èáë
- 08/2016, Ë•øÈó®Â≠êÊùØ‰∏≠ÂõΩÊô∫ËÉΩÂà∂ÈÄ†ÊåëÊàòËµõÂÖ®ÂõΩÁâπÁ≠âÂ•ñ

# üìñ Educations
- 09/2017 - 08/2022, Ph.D. in Precision Instrument, Department of Precision Instrument, Tsinghua University, Beijing, China.
- 09/2013 - 07/2017, Bachelor's in Artificial Intelligence and Automation, School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China.

- 2017Âπ¥9Êúà - 2022Âπ¥8Êúà, ÂçöÂ£´, Ê∏ÖÂçéÂ§ßÂ≠¶Á≤æÂØÜ‰ª™Âô®Á≥ª, ‰∏≠ÂõΩÂåó‰∫¨
- 2013Âπ¥9Êúà - 2017Âπ¥7ÊúàÔºåÊú¨Áßë, Âçé‰∏≠ÁßëÊäÄÂ§ßÂ≠¶‰∫∫Â∑•Êô∫ËÉΩ‰∏éËá™Âä®ÂåñÂ≠¶Èô¢, ‰∏≠ÂõΩÊ≠¶Ê±â

# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.